{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and define constants\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "data_file = './Data/ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading CSV file\n",
    "\n",
    "def read_csv(file_name):\n",
    "    \"\"\"\n",
    "    Function output should be of this format-\n",
    "    [John, lives, in, New, York] [B-PER, O, O, B-LOC, I-LOC]\n",
    "    \"\"\"\n",
    "    with open(file_name, 'r', encoding = 'ISO-8859-1') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        header = next(csv_reader)\n",
    "        \n",
    "        data = []\n",
    "        word_list, tag_list = [], []\n",
    "        \n",
    "        for line in csv_reader:\n",
    "            sentence_number, word, pos, tag = line\n",
    "            \n",
    "            # Non-empty sentence shows that new sentence is started\n",
    "            if len(sentence_number) != 0:\n",
    "                if len(word_list) != 0:\n",
    "                    data.append((word_list, tag_list))\n",
    "                    word_list, tag_list = [], []\n",
    "            \n",
    "            word_list.append(str(word))\n",
    "            tag_list.append(str(tag))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new dataset files\n",
    "\n",
    "def save_dataset_files(new_data, new_data_path):\n",
    "    # Create file paths\n",
    "    sentence_path = os.path.join(new_data_path, 'sentences.txt')\n",
    "    label_path = os.path.join(new_data_path, 'labels.txt')\n",
    "    \n",
    "    # Check stale file\n",
    "    if os.path.exists(sentence_path):\n",
    "        os.remove(sentence_path)\n",
    "    if os.path.exists(label_path):\n",
    "        os.remove(label_path)\n",
    "    \n",
    "    # Write files\n",
    "    with open(sentence_path, 'w') as file_sentences:\n",
    "        with open(label_path, 'w') as file_labels:\n",
    "            for words, labels in new_data:\n",
    "                file_sentences.write(\"{}\\n\".format(\" \".join(words)))\n",
    "                file_labels.write(\"{}\\n\".format(\" \".join(labels)))\n",
    "    \n",
    "    print('Saved files: {} & {}'.format(sentence_path, label_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start: reading file\n",
      "Data size (Lines):  47958\n",
      "Sample data: \n",
      " (['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O'])\n",
      "End: reading file\n",
      "\n",
      "Splitting data into train, validation & test data\n",
      "\n",
      "Start: saving new data files\n",
      "Saved files: ./Data/Train/sentences.txt & ./Data/Train/labels.txt\n",
      "Saved files: ./Data/Validation/sentences.txt & ./Data/Validation/labels.txt\n",
      "Saved files: ./Data/Test/sentences.txt & ./Data/Test/labels.txt\n",
      "End: saving new data files\n"
     ]
    }
   ],
   "source": [
    "# Main Data-Pipeline\n",
    "\n",
    "print('\\nStart: reading file')\n",
    "data = read_csv(data_file)\n",
    "size_of_data = len(data)\n",
    "print('Data size (Lines): ', size_of_data)\n",
    "print('Sample data: \\n', data[0])\n",
    "print('End: reading file')\n",
    "\n",
    "print('\\nSplitting data into train, validation & test data')\n",
    "train_data = data[:int(0.7 * size_of_data)]\n",
    "validation_data = data[int(0.7 * size_of_data):int(0.85 * size_of_data)]\n",
    "test_data = data[int(0.85 * size_of_data):]\n",
    "\n",
    "print('\\nStart: saving new data files')\n",
    "save_dataset_files(train_data, './Data/Train')\n",
    "save_dataset_files(validation_data, './Data/Validation')\n",
    "save_dataset_files(test_data, './Data/Test')\n",
    "print('End: saving new data files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
